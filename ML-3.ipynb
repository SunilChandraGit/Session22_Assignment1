{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sunil\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "C:\\Users\\Sunil\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dta = sm.datasets.fair.load_pandas().data\n",
    "\n",
    "# add \"affair\" column: 1 represents having affairs, 0 represents not\n",
    "dta['affair'] = (dta.affairs > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Intercept', 'C(occupation)[T.2.0]', 'C(occupation)[T.3.0]',\n",
       "       'C(occupation)[T.4.0]', 'C(occupation)[T.5.0]', 'C(occupation)[T.6.0]',\n",
       "       'C(occupation_husb)[T.2.0]', 'C(occupation_husb)[T.3.0]',\n",
       "       'C(occupation_husb)[T.4.0]', 'C(occupation_husb)[T.5.0]',\n",
       "       'C(occupation_husb)[T.6.0]', 'rate_marriage', 'age', 'yrs_married',\n",
       "       'children', 'religious', 'educ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframes with an intercept column and dummy variables for\n",
    "# occupation and occupation_husb\n",
    "y, X = dmatrices('affair ~ rate_marriage + age + yrs_married + children + \\\n",
    "                  religious + educ + C(occupation) + C(occupation_husb)',\n",
    "                  dta, return_type=\"dataframe\")\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix column names of X\n",
    "X = X.rename(columns = {'C(occupation)[T.2.0]':'occ_2',\n",
    "                        'C(occupation)[T.3.0]':'occ_3',\n",
    "                        'C(occupation)[T.4.0]':'occ_4',\n",
    "                        'C(occupation)[T.5.0]':'occ_5',\n",
    "                        'C(occupation)[T.6.0]':'occ_6',\n",
    "                        'C(occupation_husb)[T.2.0]':'occ_husb_2',\n",
    "                        'C(occupation_husb)[T.3.0]':'occ_husb_3',\n",
    "                        'C(occupation_husb)[T.4.0]':'occ_husb_4',\n",
    "                        'C(occupation_husb)[T.5.0]':'occ_husb_5',\n",
    "                        'C(occupation_husb)[T.6.0]':'occ_husb_6'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7258875274897895"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate a logistic regression model, and fit with X and y\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X, y)\n",
    "\n",
    "# check the accuracy on the training set\n",
    "lr.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Intercept', 'occ_2', 'occ_3', 'occ_4', 'occ_5', 'occ_6', 'occ_husb_2',\n",
       "        'occ_husb_3', 'occ_husb_4', 'occ_husb_5', 'occ_husb_6', 'rate_marriage',\n",
       "        'age', 'yrs_married', 'children', 'religious', 'educ'],\n",
       "       dtype='object'), array([[ 1.48983589],\n",
       "        [ 0.18806639],\n",
       "        [ 0.49894787],\n",
       "        [ 0.25066856],\n",
       "        [ 0.83900806],\n",
       "        [ 0.83390843],\n",
       "        [ 0.19063594],\n",
       "        [ 0.29783271],\n",
       "        [ 0.16140885],\n",
       "        [ 0.18777091],\n",
       "        [ 0.19401637],\n",
       "        [-0.70312336],\n",
       "        [-0.05841777],\n",
       "        [ 0.10567654],\n",
       "        [ 0.01691927],\n",
       "        [-0.37113627],\n",
       "        [ 0.0040165 ]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the coefficients\n",
    "X.columns, np.transpose(lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Increases in marriage rating and religiousness correspond to a decrease in the likelihood of having an affair.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model Evaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the datasets into traing and test dataset respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict class labels for the test set\n",
    "predicted = model2.predict(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3514634 , 0.6485366 ],\n",
       "       [0.90955084, 0.09044916],\n",
       "       [0.72567333, 0.27432667],\n",
       "       ...,\n",
       "       [0.55727385, 0.44272615],\n",
       "       [0.81207043, 0.18792957],\n",
       "       [0.74734601, 0.25265399]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate class probabilities\n",
    "probs = model2.predict_proba(X_test)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7298429319371728\n",
      "0.745950606950631\n"
     ]
    }
   ],
   "source": [
    "# generate evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, predicted))\n",
    "print(metrics.roc_auc_score(y_test, probs[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The accuracy is around 73%</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
